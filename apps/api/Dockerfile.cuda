# apps/api/Dockerfile.cuda
#
# CUDA-capable image for:
# - FastAPI API service
# - One-shot ingest job (GPU embeddings)
#
# Requires NVIDIA Container Toolkit (Linux) or Docker Desktop GPU support (Windows).

FROM pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime AS base

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PIP_NO_CACHE_DIR=1

WORKDIR /app

# System deps:
# - curl/ca-certificates: healthchecks, debugging, TLS
# - build-essential: occasional wheels need compilation
# - git: optional, but handy if you ever vendor or inspect repos in-container
RUN apt-get update && apt-get install -y --no-install-recommends \
      ca-certificates \
      curl \
      git \
      build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies first for better layer caching
COPY apps/api/requirements.base.txt /app/requirements.base.txt
COPY apps/api/requirements.cuda.txt /app/requirements.cuda.txt
RUN python -m pip install --upgrade pip \
    && pip install -r /app/requirements.cuda.txt

# Copy the API application code (including alembic files)
COPY apps/api /app/apps/api

# Make apps/api the default working directory so `alembic` just works
WORKDIR /app/apps/api

EXPOSE 8000

# Default command for the API container.
# docker-compose can override this for ingest jobs.
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
